// === C·∫§U H√åNH V√Ä BI·∫æN TO√ÄN C·ª§C ===
const video = document.getElementById('video');
const statusDiv = document.getElementById('status');
const personDiv = document.getElementById('person');

// === KH·ªûI T·∫†O M√î H√åNH NH·∫¨N DI·ªÜN ===
Promise.all([
  faceapi.nets.tinyFaceDetector.loadFromUri('./model'),
  faceapi.nets.faceLandmark68Net.loadFromUri('./model'),
  faceapi.nets.faceRecognitionNet.loadFromUri('./model'),
  faceapi.nets.ssdMobilenetv1.loadFromUri('./model'), // m√¥ h√¨nh ch√≠nh x√°c h∆°n
]).then(startVideo)
  .catch(err => {
    statusDiv.innerText = `‚ùå L·ªói t·∫£i model: ${err.message}`;
  });

// === H√ÄM KH·ªûI ƒê·ªòNG CAMERA ===
function startVideo() {
  navigator.mediaDevices
    .getUserMedia({ video: {} })
    .then(stream => {
      video.srcObject = stream;
    })
    .catch(err => {
      console.error("Camera error:", err);
      statusDiv.innerText = `‚ö†Ô∏è Kh√¥ng th·ªÉ truy c·∫≠p camera: ${err.message}`;
      alert("H√£y b·∫≠t quy·ªÅn truy c·∫≠p camera trong tr√¨nh duy·ªát ƒë·ªÉ ti·∫øp t·ª•c!");
    });
}

// === S·ª∞ KI·ªÜN KHI CAMERA S·∫¥N S√ÄNG ===
video.addEventListener('play', async () => {
  statusDiv.innerText = 'üîç ƒêang t·∫£i d·ªØ li·ªáu khu√¥n m·∫∑t...';

  // Danh s√°ch ng∆∞·ªùi c·∫ßn nh·∫≠n di·ªán (t√™n file ph·∫£i tr√πng trong /known_faces/)
  const labels = ['nguyen_tuan_anh', 'tran_b'];

  // T·∫£i d·ªØ li·ªáu khu√¥n m·∫∑t ƒë√£ bi·∫øt
  const labeledFaceDescriptors = await Promise.all(
    labels.map(async label => {
      const descriptions = [];
      for (let i = 1; i <= 1; i++) { // c√≥ th·ªÉ tƒÉng l√™n n·∫øu c√≥ nhi·ªÅu ·∫£nh
        const imgUrl = `./known_faces/${label}.jpg`;
        console.log(`ƒêang t·∫£i ·∫£nh: ${imgUrl}`);
        try {
          const img = await faceapi.fetchImage(imgUrl);
          const detection = await faceapi
            .detectSingleFace(img)
            .withFaceLandmarks()
            .withFaceDescriptor();
          if (!detection) {
            console.warn(`‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t trong ${imgUrl}`);
            continue;
          }
          descriptions.push(detection.descriptor);
        } catch (e) {
          console.error(`‚ùå L·ªói t·∫£i ·∫£nh ${imgUrl}:`, e);
        }
      }
      return new faceapi.LabeledFaceDescriptors(label, descriptions);
    })
  );

  statusDiv.innerText = '‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu khu√¥n m·∫∑t. H·ªá th·ªëng ƒëang nh·∫≠n di·ªán...';

  // Kh·ªüi t·∫°o FaceMatcher (ƒë·ªô ch√≠nh x√°c: 0.6 c√†ng th·∫•p c√†ng kh·∫Øt khe)
  const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.8);

  // T·∫°o canvas ƒë·ªÉ hi·ªÉn th·ªã khung nh·∫≠n di·ªán
  const canvas = faceapi.createCanvasFromMedia(video);
  document.body.append(canvas);
  const displaySize = { width: video.width, height: video.height };
  faceapi.matchDimensions(canvas, displaySize);

  // === NH·∫¨N DI·ªÜN THEO TH·ªúI GIAN TH·ª∞C ===
  setInterval(async () => {
    const detections = await faceapi
      .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceDescriptors();

    const resizedDetections = faceapi.resizeResults(detections, displaySize);
    const context = canvas.getContext('2d');
    context.clearRect(0, 0, canvas.width, canvas.height);

    const results = resizedDetections.map(d =>
      faceMatcher.findBestMatch(d.descriptor)
    );

    results.forEach((result, i) => {
      const box = resizedDetections[i].detection.box;
      const drawBox = new faceapi.draw.DrawBox(box, { label: result.toString() });
      drawBox.draw(canvas);

      if (result.label !== "unknown") {
        personDiv.innerText = `üë§ Xin ch√†o ${result.label.toUpperCase()}!`;
      } else {
        personDiv.innerText = `‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t.`;
      }
    });
  }, 1000);
});

